---
phase: 03-voice-commands
plan: 02
type: execute
wave: 2
depends_on: ["03-01"]
files_modified:
  - apps/telegram-bot/src/handlers/voice.ts
  - apps/telegram-bot/src/handlers/index.ts
  - apps/telegram-bot/src/index.ts
autonomous: true

must_haves:
  truths:
    - "Kimmie speaks a question and gets the same answer she would if she typed it"
    - "Voice queries return client/pet profiles just like typed /lookup commands"
    - "Kimmie can work hands-free without touching her phone to search"
  artifacts:
    - path: "apps/telegram-bot/src/handlers/voice.ts"
      provides: "Voice message handler"
      exports: ["voiceHandler"]
  key_links:
    - from: "apps/telegram-bot/src/handlers/voice.ts"
      to: "apps/telegram-bot/src/services/transcription.ts"
      via: "transcribeAudio import"
      pattern: "transcribeAudio\\("
    - from: "apps/telegram-bot/src/handlers/voice.ts"
      to: "apps/telegram-bot/src/services/natural-language.ts"
      via: "processNaturalLanguageQuery import"
      pattern: "processNaturalLanguageQuery\\("
    - from: "apps/telegram-bot/src/handlers/voice.ts"
      to: "apps/telegram-bot/src/services/formatting.ts"
      via: "formatClientProfile, formatClientList imports for rendering results"
      pattern: "formatClient(Profile|List)"
    - from: "apps/telegram-bot/src/index.ts"
      to: "apps/telegram-bot/src/handlers/voice.ts"
      via: "voiceHandler registration before catch-all"
      pattern: "bot\\.use\\(voiceHandler\\)"
---

<objective>
Create the voice message handler that uses transcription and natural language services to process voice queries and return formatted results.

Purpose: This is the final piece - connecting the voice message event to transcription, query processing, and response rendering so Kimmie gets hands-free lookups.

Output:
- Voice handler that transcribes voice messages via Whisper
- Query processing via natural language service
- Formatted responses using existing formatting service
- Handler registered in correct position (before catch-all)
</objective>

<execution_context>
@/home/bitvise/.claude/get-shit-done/workflows/execute-plan.md
@/home/bitvise/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/03-voice-commands/03-RESEARCH.md
@.planning/phases/03-voice-commands/03-01-SUMMARY.md

# Key source files
@apps/telegram-bot/src/services/transcription.ts
@apps/telegram-bot/src/services/natural-language.ts
@apps/telegram-bot/src/services/formatting.ts
@apps/telegram-bot/src/handlers/index.ts
@apps/telegram-bot/src/index.ts
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create voice handler with full wiring</name>
  <files>
    apps/telegram-bot/src/handlers/voice.ts
    apps/telegram-bot/src/handlers/index.ts
    apps/telegram-bot/src/index.ts
  </files>
  <action>
1. Create voice handler at apps/telegram-bot/src/handlers/voice.ts:
   - Import Composer from grammy
   - Import transcribeAudio from services/transcription
   - Import processNaturalLanguageQuery, NLQueryResult from services/natural-language
   - Import formatClientProfile, formatClientList from services/formatting (for rendering results)
   - Import fs/promises for file cleanup
   - Handle 'message:voice' events:
     a. Send typing indicator: `await ctx.replyWithChatAction('typing')`
     b. Download voice file: `const file = await ctx.getFile(); const filePath = await file.download();`
     c. Transcribe: `const text = await transcribeAudio(filePath)`
     d. Clean up temp file: `await fs.unlink(filePath).catch(() => {})` (prevent disk bloat)
     e. Handle empty transcription: reply with "Couldn't hear anything - try again?"
     f. Echo transcription: `await ctx.reply('I heard: "${text}"')`
     g. Process query: `const result = await processNaturalLanguageQuery(text)`
     h. Render based on result.type:
        - 'client': ctx.reply(formatClientProfile(result.data), { parse_mode: 'HTML' })
        - 'clients': ctx.reply(formatClientList(result.data), { parse_mode: 'HTML' })
        - 'not_found': ctx.reply(result.message)
   - Wrap all in try-catch, reply with friendly fallback on error

Key pattern:
```typescript
import { Composer } from 'grammy';
import type { BotContext } from '../bot';
import { transcribeAudio } from '../services/transcription';
import { processNaturalLanguageQuery } from '../services/natural-language';
import { formatClientProfile, formatClientList } from '../services/formatting';
import fs from 'fs/promises';

export const voiceHandler = new Composer<BotContext>();

voiceHandler.on('message:voice', async (ctx) => {
  let filePath: string | undefined;

  try {
    await ctx.replyWithChatAction('typing');
    const file = await ctx.getFile();
    filePath = await file.download();
    const transcription = await transcribeAudio(filePath);

    // Clean up temp file immediately after transcription
    await fs.unlink(filePath).catch(() => {});
    filePath = undefined;

    if (!transcription?.trim()) {
      await ctx.reply("Couldn't hear anything - try again?");
      return;
    }

    await ctx.reply(`I heard: "${transcription}"`);

    const result = await processNaturalLanguageQuery(transcription);

    switch (result.type) {
      case 'client':
        await ctx.reply(formatClientProfile(result.data), { parse_mode: 'HTML' });
        break;
      case 'clients':
        await ctx.reply(formatClientList(result.data), { parse_mode: 'HTML' });
        break;
      case 'not_found':
        await ctx.reply(result.message);
        break;
    }
  } catch (error) {
    // Clean up on error too
    if (filePath) {
      await fs.unlink(filePath).catch(() => {});
    }
    console.error('Voice transcription error:', error);
    await ctx.reply("Couldn't understand that - try again or type your question");
  }
});
```

2. Export voice handler from handlers/index.ts:
   - Add `export { voiceHandler } from './voice'`

3. Register voice handler in index.ts:
   - Import voiceHandler from handlers
   - Add `bot.use(voiceHandler)` BEFORE the catch-all text handler
   - Order: helpHandler, lookupHandler, voiceHandler, bookingsHandler, ...
   - NOTE: voiceHandler handles 'message:voice', lookupHandler handles 'message:text', so order matters for any shared callback queries
  </action>
  <verify>
- `cd apps/telegram-bot && npx tsc --noEmit` passes without errors
- voice.ts exports voiceHandler: `grep "export.*voiceHandler" apps/telegram-bot/src/handlers/voice.ts`
- handlers/index.ts exports voiceHandler: `grep "voiceHandler" apps/telegram-bot/src/handlers/index.ts`
- voice.ts imports formatClientProfile: `grep "formatClientProfile" apps/telegram-bot/src/handlers/voice.ts`
- voice.ts imports formatClientList: `grep "formatClientList" apps/telegram-bot/src/handlers/voice.ts`
- voice.ts cleans up temp file: `grep "unlink" apps/telegram-bot/src/handlers/voice.ts`
- Verify handler registration order: `grep -A5 "bot.use(voiceHandler)" apps/telegram-bot/src/index.ts`
  </verify>
  <done>
- voice.ts handles message:voice events with transcription + NL processing + formatting
- voice.ts imports and uses formatClientProfile, formatClientList for rendering
- voice.ts cleans up downloaded audio files after transcription
- voiceHandler exported from handlers/index.ts
- voiceHandler registered in index.ts before catch-all text handler
- All TypeScript compiles without errors
  </done>
</task>

</tasks>

<verification>
1. TypeScript compilation: `cd apps/telegram-bot && npx tsc --noEmit` passes
2. Voice handler properly wired to all services (transcription, NL, formatting)
3. Handler registered before catch-all in index.ts
4. Temp file cleanup implemented
</verification>

<success_criteria>
1. Voice handler transcribes voice messages via Whisper API
2. Voice handler processes transcription via processNaturalLanguageQuery
3. Voice handler formats results via formatClientProfile/formatClientList
4. Voice handler cleans up temp audio files after transcription
5. Handler registered before catch-all text handler
6. All TypeScript compiles without errors
</success_criteria>

<output>
After completion, create `.planning/phases/03-voice-commands/03-02-SUMMARY.md`
</output>
