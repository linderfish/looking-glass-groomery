---
phase: 03-voice-commands
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - apps/telegram-bot/package.json
  - apps/telegram-bot/src/bot.ts
  - apps/telegram-bot/src/services/transcription.ts
  - apps/telegram-bot/src/services/natural-language.ts
  - apps/telegram-bot/src/handlers/voice.ts
  - apps/telegram-bot/src/handlers/lookup.ts
  - apps/telegram-bot/src/handlers/index.ts
  - apps/telegram-bot/src/index.ts
autonomous: true

must_haves:
  truths:
    - "Kimmie sends a voice message and it gets transcribed accurately"
    - "The transcribed text is understood by Cheshire (lookups, questions all work)"
    - "Kimmie receives a text response she can glance at while grooming"
  artifacts:
    - path: "apps/telegram-bot/src/services/transcription.ts"
      provides: "Whisper API wrapper for audio transcription"
      exports: ["transcribeAudio"]
    - path: "apps/telegram-bot/src/services/natural-language.ts"
      provides: "Extracted natural language query processing"
      exports: ["processNaturalLanguageQuery"]
    - path: "apps/telegram-bot/src/handlers/voice.ts"
      provides: "Voice message handler"
      exports: ["voiceHandler"]
  key_links:
    - from: "apps/telegram-bot/src/handlers/voice.ts"
      to: "apps/telegram-bot/src/services/transcription.ts"
      via: "transcribeAudio import"
      pattern: "transcribeAudio\\("
    - from: "apps/telegram-bot/src/handlers/voice.ts"
      to: "apps/telegram-bot/src/services/natural-language.ts"
      via: "processNaturalLanguageQuery import"
      pattern: "processNaturalLanguageQuery\\("
    - from: "apps/telegram-bot/src/bot.ts"
      to: "@grammyjs/files"
      via: "hydrateFiles plugin configuration"
      pattern: "hydrateFiles"
---

<objective>
Add voice message handling to the Telegram bot so Kimmie can speak queries while grooming with wet/dirty hands and receive text responses.

Purpose: Hands-free operation is critical - Kimmie's hands are often wet or covered in dog hair during grooming. Voice commands let her query client/pet info without touching her phone.

Output:
- @grammyjs/files plugin installed and configured
- Transcription service using OpenAI Whisper API
- Voice handler that transcribes and processes via natural language service
- Refactored lookup handler to extract shared natural language logic
</objective>

<execution_context>
@/home/bitvise/.claude/get-shit-done/workflows/execute-plan.md
@/home/bitvise/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/03-voice-commands/03-RESEARCH.md

# Key source files
@apps/telegram-bot/src/bot.ts
@apps/telegram-bot/src/handlers/lookup.ts
@apps/telegram-bot/src/handlers/index.ts
@apps/telegram-bot/src/index.ts
@apps/telegram-bot/package.json
</context>

<tasks>

<task type="auto">
  <name>Task 1: Voice infrastructure setup</name>
  <files>
    apps/telegram-bot/package.json
    apps/telegram-bot/src/bot.ts
    apps/telegram-bot/src/services/transcription.ts
  </files>
  <action>
1. Install @grammyjs/files plugin:
   ```bash
   cd apps/telegram-bot && npm install @grammyjs/files
   ```

2. Configure files plugin in bot.ts:
   - Import `hydrateFiles` from `@grammyjs/files`
   - After creating the bot, add: `_bot.api.config.use(hydrateFiles(_bot.token))`
   - This MUST be done inside getBot() before any handlers are registered

3. Create transcription service at apps/telegram-bot/src/services/transcription.ts:
   - Import OpenAI from 'openai' (use same pattern as @looking-glass/ai)
   - Create transcribeAudio(filePath: string): Promise<string> function
   - Use openai.audio.transcriptions.create with model 'whisper-1'
   - Handle errors gracefully, throw Error('Transcription failed') on failure
   - File is already in OGG format from Telegram - send directly, no conversion needed

Key patterns from research:
```typescript
import OpenAI from 'openai';
import fs from 'fs';

const openai = new OpenAI({
  apiKey: process.env.OPENAI_API_KEY,
});

export async function transcribeAudio(filePath: string): Promise<string> {
  const transcription = await openai.audio.transcriptions.create({
    file: fs.createReadStream(filePath),
    model: 'whisper-1',
  });
  return transcription.text;
}
```
  </action>
  <verify>
- `npm ls @grammyjs/files` shows installed version
- transcription.ts compiles without errors (check with `npx tsc --noEmit` in apps/telegram-bot)
- bot.ts includes hydrateFiles configuration
  </verify>
  <done>
- @grammyjs/files is a dependency in package.json
- bot.ts configures hydrateFiles plugin
- transcription.ts exports transcribeAudio function
  </done>
</task>

<task type="auto">
  <name>Task 2: Voice handler with natural language extraction</name>
  <files>
    apps/telegram-bot/src/services/natural-language.ts
    apps/telegram-bot/src/handlers/voice.ts
    apps/telegram-bot/src/handlers/lookup.ts
    apps/telegram-bot/src/handlers/index.ts
    apps/telegram-bot/src/index.ts
  </files>
  <action>
1. Create natural-language.ts service - extract the query processing logic from lookup.ts:
   - Export `processNaturalLanguageQuery(query: string): Promise<NLQueryResult>`
   - NLQueryResult = { type: 'client' | 'clients' | 'not_found', data: any, message: string }
   - Move phone detection logic (regex for phone numbers)
   - Move natural language patterns (who's, find, show me, lookup, do we have)
   - Move pet hint filtering logic
   - Move pet-by-name/breed fallback search
   - Return formatted result with message and data for rendering

2. Refactor lookup.ts to use the extracted service:
   - Import processNaturalLanguageQuery from natural-language.ts
   - In the 'message:text' handler, call processNaturalLanguageQuery
   - Based on result.type, call showClientProfile or showClientList
   - Keep keyboard creation and showClientProfile/showClientList functions in lookup.ts (they need ctx)

3. Create voice handler at apps/telegram-bot/src/handlers/voice.ts:
   - Import Composer from grammy
   - Import transcribeAudio from services/transcription
   - Import processNaturalLanguageQuery from services/natural-language
   - Import formatClientProfile, formatClientList from services/formatting
   - Handle 'message:voice' events:
     a. Send typing indicator: `await ctx.replyWithChatAction('typing')`
     b. Download voice file: `const file = await ctx.getFile(); const path = await file.download();`
     c. Transcribe: `const text = await transcribeAudio(path)`
     d. Echo transcription: `await ctx.reply('I heard: "${text}"')`
     e. Process query: `const result = await processNaturalLanguageQuery(text)`
     f. Reply based on result type (use formatted message, include inline keyboard for navigation)
   - Wrap all in try-catch, reply with friendly fallback on error

4. Export voice handler from handlers/index.ts:
   - Add `export { voiceHandler } from './voice'`

5. Register voice handler in index.ts:
   - Import voiceHandler
   - Add `bot.use(voiceHandler)` BEFORE the catch-all text handler
   - Order: helpHandler, lookupHandler, voiceHandler, bookingsHandler, ...

Key pattern from research for voice handler:
```typescript
voiceHandler.on('message:voice', async (ctx) => {
  try {
    await ctx.replyWithChatAction('typing');
    const file = await ctx.getFile();
    const path = await file.download();
    const transcription = await transcribeAudio(path);

    if (!transcription?.trim()) {
      await ctx.reply("Couldn't hear anything - try again?");
      return;
    }

    await ctx.reply(`I heard: "${transcription}"`);

    const result = await processNaturalLanguageQuery(transcription);
    // Render result based on type...
  } catch (error) {
    console.error('Voice transcription error:', error);
    await ctx.reply("Couldn't understand that - try again or type your question");
  }
});
```
  </action>
  <verify>
- `npx tsc --noEmit` in apps/telegram-bot passes without errors
- All files export expected symbols
- Handler registration order in index.ts is correct (voiceHandler before catch-all)
  </verify>
  <done>
- natural-language.ts exports processNaturalLanguageQuery
- lookup.ts uses processNaturalLanguageQuery (no duplicate logic)
- voice.ts handles message:voice events with transcription + NL processing
- voiceHandler exported from handlers/index.ts
- voiceHandler registered in index.ts
  </done>
</task>

</tasks>

<verification>
1. TypeScript compilation: `cd apps/telegram-bot && npx tsc --noEmit` passes
2. Dependencies installed: @grammyjs/files in package.json
3. All new files exist and export expected symbols
4. Handler chain is correctly ordered in index.ts
</verification>

<success_criteria>
1. @grammyjs/files plugin is installed and configured in bot.ts
2. transcribeAudio service calls OpenAI Whisper API
3. processNaturalLanguageQuery extracts shared logic from lookup handler
4. Voice handler transcribes voice messages and processes via NL service
5. Lookup handler still works (uses same NL service)
6. All TypeScript compiles without errors
</success_criteria>

<output>
After completion, create `.planning/phases/03-voice-commands/03-01-SUMMARY.md`
</output>
